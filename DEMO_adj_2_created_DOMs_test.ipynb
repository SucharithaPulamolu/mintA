{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pertubation of the apex edge-created domains"
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:05.083778Z",
     "start_time": "2024-11-11T02:06:03.087561Z"
    }
   },
   "source": [
    "from src.loader import load_graph\n",
    "from classes import extract_all_features_single \n",
    "import sys\n",
    "import os\n",
    "from src import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from src.utils import largest_indices\n",
    "from src.utils import cal_n_add_facni \n",
    "from src.utils import extract_feat_adj2\n",
    "from src.utils import calc_cad \n",
    "import networkx as nx\n",
    "from scipy import spatial\n",
    "import copy  \n",
    "from matplotlib import pyplot as plt \n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routines"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:08.090177Z",
     "start_time": "2024-11-11T02:06:08.077195Z"
    }
   },
   "source": [
    "def confid_measures(arr_tri, Num):\n",
    "    arr_tri_mean = np.mean(arr_tri, axis=0)\n",
    "    std = np.std(arr_tri, axis=0)\n",
    "    Z = 1.960  # for 95 conf.\n",
    "    upper = arr_tri_mean + Z * std / np.sqrt(Num)\n",
    "    lower = arr_tri_mean - Z * std / np.sqrt(Num)\n",
    "    return np.sort(arr_tri_mean), np.sort(lower), np.sort(upper)\n",
    "\n",
    "def find_my_soln(WW):\n",
    "    ATA = np.dot(WW, WW.T)\n",
    "    w, v = np.linalg.eig(ATA)\n",
    "    return v[:, 0]\n",
    "\n",
    "def flip_the_bins(x, lox, device):\n",
    "    m = np.zeros_like(x)\n",
    "    m[:, lox] = 1\n",
    "    x_bol = np.array(x, dtype=bool)\n",
    "    m_bol = np.array(m, dtype=bool)\n",
    "    x2 = np.logical_xor(x_bol, m_bol)\n",
    "    x2 = x2.astype(float)\n",
    "    x2 = torch.from_numpy(x2).to(device)\n",
    "    return x2\n",
    "\n",
    "def preds_of_adv(model0, data, adv_nodes_test):\n",
    "    with torch.no_grad():\n",
    "        model0.eval()\n",
    "    pred_raw0 = model0(data.x_dict, data.edge_index_dict)\n",
    "    y0_hat = pred_raw0.argmax(dim=-1)\n",
    "    preds = y0_hat[adv_nodes_test]\n",
    "    return preds\n",
    "\n",
    "def my_own_acc(a, b):\n",
    "    acc = np.sum(np.equal(a, b)) / len(a)\n",
    "    return acc\n",
    "\n",
    "def my_score(pred, labels):\n",
    "    accuracy = (pred == labels).sum() / len(pred)\n",
    "    return accuracy\n",
    "\n",
    "def model_qurey(model, data, idx_train):\n",
    "    model.eval()\n",
    "    pred_raw2 = model(data.x_dict, data.edge_index_dict)\n",
    "    pred_raw2 = F.softmax(pred_raw2, dim=1)\n",
    "    y2_hat = pred_raw2.argmax(dim=-1)\n",
    "    labels_sur = y2_hat[idx_train]    \n",
    "    return labels_sur\n",
    "\n",
    "def randbin(M, N, P):  \n",
    "    return np.random.choice([0, 1], size=(M, N), p=[P, 1 - P])\n",
    "\n",
    "def do_perturb_feat(x, m, device):\n",
    "    x_bol = np.array(x, dtype=bool)\n",
    "    m_bol = np.array(m, dtype=bool)\n",
    "    x2 = np.logical_xor(x_bol, m_bol)\n",
    "    x2 = x2.astype(float)\n",
    "    x2 = torch.from_numpy(x2).to(device)\n",
    "    return x2\n",
    "\n",
    "def do_perturb_adj(a, m, device):\n",
    "    a_bol = np.array(a, dtype=bool)\n",
    "    m_bol = np.array(m, dtype=bool)\n",
    "    a2 = np.logical_xor(a_bol, m_bol)\n",
    "    a2 = a2.astype(float)\n",
    "    a2 = torch.from_numpy(a2).to(device)\n",
    "    return a2\n",
    "\n",
    "def A_to_edge_index(A, device):\n",
    "    adj_t = torch.tensor(A).to(device)\n",
    "    edge_index = adj_t.nonzero().t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "def assign_Adversary_nas_mal(data, norm_zero_int):\n",
    "    test_mask = data['domain_node']['test_mask']\n",
    "    labels_test=data['domain_node'].y[test_mask].cpu()\n",
    "    lox_test=np.where(test_mask.cpu()>0)\n",
    "    lox_test=lox_test[0]\n",
    "    labels=data['domain_node'].y.cpu()\n",
    "    lox_test_space=lox_test[np.where(labels_test.cpu()==1) ] #mal\n",
    "    adv_nodes_test=random.sample(set(lox_test_space), norm_zero_int)   \n",
    "    return adv_nodes_test\n",
    "\n",
    "def get_As_new(adj_1, adj_2, adj_3, adj_4, adv_nodes):\n",
    "    \n",
    "    edge_list= np.concatenate(( adj_2.cpu(), adj_4.cpu()), axis=1)\n",
    "   \n",
    "    all_edges1=edge_list[0,:]\n",
    "    all_edges2=edge_list[1,:]\n",
    "\n",
    "    adv_edge_lox1= np.nonzero(np.in1d(all_edges1, adv_nodes))[0]\n",
    "    adv_edge_lox2= np.nonzero(np.in1d(all_edges2, adv_nodes))[0]\n",
    "\n",
    "    A_adv=np.zeros( (len(adv_nodes),len(adv_nodes)), dtype=int)\n",
    "    adv_nodes=np.array(adv_nodes)\n",
    "    adv_edge_lox1=np.array(adv_edge_lox1)\n",
    "    adv_edge_lox2=np.array(adv_edge_lox2)\n",
    "\n",
    "    for k in range(adv_edge_lox1.shape[0]):\n",
    "        a=all_edges1[adv_edge_lox1[k]]\n",
    "        b=all_edges2[adv_edge_lox2[k]]\n",
    "        lox_a=np.where(adv_nodes == np.array(a))\n",
    "        lox_b=np.where(adv_nodes == np.array(b))\n",
    "        A_adv[lox_a,lox_b]=1 \n",
    "    print(\"resssss\", np.count_nonzero(A_adv))\n",
    "   \n",
    "    return A_adv\n",
    "\n",
    "def edge_list_to_adj(adv_edge_list):\n",
    "    elist=adv_edge_list.cpu()\n",
    "    domain_node_list=np.unique(elist[0,:])\n",
    "    A=np.zeros( (len(domain_node_list),len(domain_node_list)), dtype=int)\n",
    "    for k in range(len(elist)):\n",
    "        a=elist[k][0]\n",
    "        b=elist[k][1]\n",
    "        lox_a=np.where(domain_node_list == a)\n",
    "        lox_b=np.where(domain_node_list == b)\n",
    "        A[lox_a,lox_b]=1\n",
    "    return A\n",
    "\n",
    "def extract_A(data, adv_nodes):\n",
    "    edge_list_1=data.edge_index_dict['domain_node', 'apex', 'domain_node'][0,:]\n",
    "    edge_list=data.edge_index_dict['domain_node', 'apex', 'domain_node']\n",
    "#     adv_nodes=np.array([0,1,4,5,6])\n",
    "    common_node_lox=np.nonzero(np.in1d(edge_list_1.cpu(), adv_nodes))[0]\n",
    "    adv_edge_list=edge_list[:,common_node_lox]\n",
    "#     print(adv_edge_list)\n",
    "    A_adv=edge_list_to_adj(adv_edge_list.cpu())\n",
    "    return A_adv\n",
    "\n",
    "def edge_list_to_adj(adv_edge_lox1, adv_edge_lox2):\n",
    "    elist=adv_edge_lox2\n",
    "    print(elist)\n",
    "    domain_node_list=np.unique(elist)\n",
    "    domain_node_list=domain_node_list[0:4000]\n",
    "    A=np.zeros( (len(domain_node_list),len(domain_node_list)), dtype=int)\n",
    "    for k in range(len(elist)):\n",
    "        a=adv_edge_lox1[k]\n",
    "        b=adv_edge_lox2[k]\n",
    "        lox_a=np.where(domain_node_list == a)\n",
    "        lox_b=np.where(domain_node_list == b)\n",
    "        A[lox_a,lox_b]=1\n",
    "    return A\n",
    "\n",
    "def extract_As_jan(data, adv_nodes):\n",
    "    edge_list=data.edge_index_dict['domain_node', 'apex', 'domain_node']\n",
    "    all_edges1=edge_list[0,:]\n",
    "    all_edges2=edge_list[1,:]\n",
    "    \n",
    "    all_edges1=all_edges1.cpu()\n",
    "    all_edges2=all_edges2.cpu()\n",
    "\n",
    "    adv_edge_lox1= np.nonzero(np.in1d(all_edges1, adv_nodes))[0]\n",
    "    adv_edge_lox2= np.nonzero(np.in1d(all_edges2, adv_nodes))[0]\n",
    "\n",
    "#     adv_edge_list=edge_list[:,adv_edge_lox]\n",
    "    L=len(adv_nodes)\n",
    "    A_adv1=np.zeros( (L,L), dtype=int)\n",
    "    adv_nodes=np.array(adv_nodes)\n",
    "    adv_edge_lox1=np.array(adv_edge_lox1)\n",
    "    adv_edge_lox2=np.array(adv_edge_lox2)\n",
    "\n",
    "    for k in range(adv_edge_lox1.shape[0]):\n",
    "        a=all_edges1[adv_edge_lox1[k]]\n",
    "        b=all_edges2[adv_edge_lox2[k]]\n",
    "        lox_a=np.where(adv_nodes == np.array(a))\n",
    "        lox_b=np.where(adv_nodes == np.array(b))\n",
    "#         print(lox_a, lox_b)\n",
    "        A_adv1[lox_a,lox_b]=1\n",
    "        \n",
    "    print(\"sparsity\", np.count_nonzero(A_adv1))    \n",
    "    \n",
    "    \n",
    "    edge_list=data.edge_index_dict['domain_node', 'apex', 'domain_node']\n",
    "    all_edges1=edge_list[0,:]\n",
    "    all_edges2=edge_list[1,:]\n",
    "    \n",
    "    all_edges1=all_edges1.cpu()\n",
    "    all_edges2=all_edges2.cpu()\n",
    "\n",
    "    adv_edge_lox1= np.nonzero(np.in1d(all_edges1, adv_nodes))[0]\n",
    "    adv_edge_lox2= np.nonzero(np.in1d(all_edges2, adv_nodes))[0]\n",
    "\n",
    "#     adv_edge_list=edge_list[:,adv_edge_lox]\n",
    "    L=len(adv_nodes)\n",
    "    A_adv2=np.zeros( (L,L), dtype=int)\n",
    "    adv_nodes=np.array(adv_nodes)\n",
    "    adv_edge_lox1=np.array(adv_edge_lox1)\n",
    "    adv_edge_lox2=np.array(adv_edge_lox2)\n",
    "\n",
    "    for k in range(adv_edge_lox1.shape[0]):\n",
    "        a=all_edges1[adv_edge_lox1[k]]\n",
    "        b=all_edges2[adv_edge_lox2[k]]\n",
    "        lox_a=np.where(adv_nodes == np.array(a))\n",
    "        lox_b=np.where(adv_nodes == np.array(b))\n",
    "#         print(lox_a, lox_b)\n",
    "        A_adv2[lox_a,lox_b]=1\n",
    "        \n",
    "    print(\"sparsity\", np.count_nonzero(A_adv2)) \n",
    "    \n",
    "    \n",
    "    A_adv=A_adv1+A_adv2\n",
    "    \n",
    "    return A_adv\n",
    "\n",
    "def calc_ASR(data, adv_nodes_test, model0):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model0.eval()\n",
    "        pred_raw0 = model0(data.x_dict, data.edge_index_dict)\n",
    "        pred_raw0 = F.softmax(pred_raw0, dim=1)\n",
    "        y0_hat= pred_raw0.argmax(dim=-1)\n",
    "        \n",
    "    y0_hat=y0_hat[adv_nodes_test]    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        model0.eval()\n",
    "        pred_raw2 = model0(data.x_dict2, data.edge_index_dict2)\n",
    "        pred_raw2 = F.softmax(pred_raw2, dim=1)\n",
    "        y2_hat= pred_raw2.argmax(dim=-1)\n",
    "    y2_hat=y2_hat[adv_nodes_test]        \n",
    "\n",
    "    num_of_1=0;\n",
    "    num_of_1_forced_to_0=0;\n",
    "    num_of_0=0;\n",
    "    num_of_0_forced_to_1=0;\n",
    "    \n",
    "    for jj in range(len(y0_hat)):\n",
    "        if y0_hat[jj]==1:\n",
    "            num_of_1=num_of_1+1\n",
    "        if y0_hat[jj]==1 and y2_hat[jj]==0:\n",
    "            num_of_1_forced_to_0=num_of_1_forced_to_0+1;\n",
    "            \n",
    "        if y0_hat[jj]==0:\n",
    "            num_of_0=num_of_0+1\n",
    "        if y0_hat[jj]==0 and y2_hat[jj]==1:\n",
    "            num_of_0_forced_to_1=num_of_0_forced_to_1+1;\n",
    "            \n",
    "    if num_of_1>0:\n",
    "        ASRgood=num_of_1_forced_to_0/num_of_1\n",
    "    else:\n",
    "        ASRgood=num_of_1_forced_to_0\n",
    "\n",
    "        \n",
    "    if num_of_0>0:\n",
    "        ASRbad=num_of_0_forced_to_1/num_of_0\n",
    "    else:\n",
    "        ASRbad=num_of_0_forced_to_1\n",
    "\n",
    "    print(\"ASRgood\", ASRgood, num_of_1_forced_to_0, num_of_1, \"ASRbad\", ASRbad, num_of_0_forced_to_1, num_of_0)\n",
    "    return ASRgood, num_of_1_forced_to_0, num_of_1, ASRbad, num_of_0_forced_to_1, num_of_0\n",
    "\n",
    "def assign_Adversary_ras(data, norm_zero_int):\n",
    "    test_mask = data['domain_node']['test_mask']\n",
    "    labels_test=data['domain_node'].y[test_mask].cpu()\n",
    "    lox_test=np.where(test_mask.cpu()>0)\n",
    "    lox_test=lox_test[0]\n",
    "    labels=data['domain_node'].y.cpu()\n",
    "    lox_test_space=lox_test[np.where(labels_test.cpu()==1) ] #mal\n",
    "    adv_nodes_test=random.sample(set(lox_test_space), norm_zero_int)\n",
    "#     adv_nodes_test=lox_test_space[0:norm_zero_int]\n",
    "    return adv_nodes_test"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:14.652584Z",
     "start_time": "2024-11-11T02:06:11.111143Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.loader2 import DNS2\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "kg_path = lambda graph_name: f'/home/sucharitha/MintA/myGraph_datasets/{graph_name}'\n",
    "dataset = DNS2('myGraph_datasets/DNS', transform=T.Compose([T.NormalizeFeatures(), T.ToUndirected()]), balance_gt=True)\n",
    "data = dataset[0]\n",
    "# dir(data)\n",
    "# feats_2=cal_n_add_facni(kg_path('DNS_eid_adv'), data);\n",
    "# torch.save(feats_2, 'feats_2.pt')\n",
    "# This script is for eature extraction\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# dir(data)\n",
    "# feats_new2=cal_n_add_facni(kg_path('DNS_eid_adv'), data);\n",
    "# torch.save(feats_new2, 'feats_new2.pt')\n",
    "\n",
    "# Feature assignment \n",
    "feats_new2 = torch.load('feats_new2.pt').to(device)\n",
    "data['domain_node'].x = feats_new2[0:data.x_dict['domain_node'].shape[0], :].to(device)\n",
    "data['ip_node'].x = torch.zeros(data['ip_node'].x.shape[0], 1).to(device)\n",
    "data['host_node'].x = torch.zeros(data['host_node'].x.shape[0], 1).to(device)\n",
    "del feats_new2\n",
    "# print(data.metadata)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MDD model "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:17.248214Z",
     "start_time": "2024-11-11T02:06:17.210008Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv, HeteroConv, Linear\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels, num_layers, add_self_loops=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: GATConv((-1,-1), hidden_channels, add_self_loops=add_self_loops)\n",
    "                for edge_type in metadata[1]\n",
    "            })\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['domain_node'])\n",
    "    \n",
    "model = HeteroGNN(data.metadata(), hidden_channels=64, out_channels=2,\n",
    "                  num_layers=2)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:18.518223Z",
     "start_time": "2024-11-11T02:06:18.406507Z"
    }
   },
   "source": [
    "print(torch.cuda.device_count())\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "def train(model, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['domain_node'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['domain_node'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask', 'test_mask']:\n",
    "        mask = data[split]\n",
    "        acc = (pred[mask] == data['domain_node'].y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:19.835224Z",
     "start_time": "2024-11-11T02:06:19.832888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:25.913610Z",
     "start_time": "2024-11-11T02:06:22.461061Z"
    }
   },
   "source": [
    "from deeprobust.graph.defense import GCN\n",
    "\n",
    "# Set device for CUDA compatibility\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data to train the surrogate\n",
    "train_mask = data['domain_node'].train_mask\n",
    "labels_train = data['domain_node'].y.to(device)  # Move labels to GPU if available\n",
    "labelled_labels_train_lox = np.where(labels_train.cpu() < 2)\n",
    "lox_train = np.where(train_mask.cpu() > 0)[0]\n",
    "\n",
    "labels = data['domain_node'].y.to(device)\n",
    "lox_train_space = labelled_labels_train_lox\n",
    "adv_nodes_train = lox_train_space[0][0:4000]\n",
    "\n",
    "# Extract adjacency and features for surrogate model\n",
    "Adj_sur = extract_As_jan(data, adv_nodes_train)\n",
    "features_sur = data['domain_node'].x[adv_nodes_train].to(device)  # Ensure features are on the same device\n",
    "\n",
    "# Convert features to NumPy for compatibility with the deeprobust library, then back to CUDA tensor\n",
    "features_sur = np.array(features_sur.cpu())\n",
    "data.x_sur = torch.tensor(features_sur).to(device)\n",
    "\n",
    "# Define training indices\n",
    "idx_train = torch.arange(4000).to(device)\n",
    "\n",
    "# Initialize and train the surrogate model\n",
    "surrogate = GCN(nfeat=features_sur.shape[1], nclass=2, nhid=64, dropout=0, with_relu=False, with_bias=False, device='cpu')\n",
    "features_sur_tensor = torch.tensor(features_sur).to('cpu')  # Move features to CPU for deeprobust compatibility\n",
    "Adj_sur_tensor = torch.tensor(Adj_sur).to('cpu')  # Move adjacency to CPU\n",
    "labels_sur = labels[adv_nodes_train].to('cpu')  # Move labels to CPU\n",
    "\n",
    "# Fit surrogate model\n",
    "surrogate.fit(features_sur_tensor, Adj_sur_tensor, labels_sur, idx_train.cpu())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity 3802\n",
      "sparsity 3802\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:06:27.709343Z",
     "start_time": "2024-11-11T02:06:27.707336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The proposed MinstA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:28:09.482892Z",
     "start_time": "2024-11-11T02:28:09.472818Z"
    }
   },
   "source": [
    "def one_trial(adv_nodes_test, A_adv):   \n",
    "    # Set device for compatibility\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize and train a new model instance\n",
    "    dataset = DNS2('myGraph_datasets/DNS', transform=T.Compose([T.NormalizeFeatures(), T.ToUndirected()]), balance_gt=True)\n",
    "    data = dataset[0]\n",
    "    \n",
    "    # Load features and ensure proper type and shape compatibility\n",
    "    feats_new = torch.load('feats_new2.pt')\n",
    "    if feats_new.shape[0] < data.x_dict['domain_node'].shape[0]:\n",
    "        raise ValueError(\"The tensor 'feats_new' has fewer rows than the number of domain nodes.\")\n",
    "\n",
    "    # Assign features to nodes\n",
    "    data['domain_node'].x = feats_new[0:data.x_dict['domain_node'].shape[0], :]\n",
    "    data['ip_node'].x = torch.zeros(data['ip_node'].x.shape[0], 1)\n",
    "    data['host_node'].x = torch.zeros(data['host_node'].x.shape[0], 1)\n",
    "    del feats_new\n",
    "\n",
    "    # Validate tensors before moving them to the device\n",
    "    for key, value in data.x_dict.items():\n",
    "        if torch.isnan(value).any() or torch.isinf(value).any():\n",
    "            raise ValueError(f\"The tensor {key} contains NaN or Inf values, which will cause issues during device transfer.\")\n",
    "        if value.shape[0] == 0:\n",
    "            raise ValueError(f\"The tensor {key} has no rows, which is not valid.\")\n",
    "\n",
    "    # Ensure all edge indices are of type long and filter out invalid edge indices\n",
    "    for key, edge_index in data.edge_index_dict.items():\n",
    "        data.edge_index_dict[key] = edge_index.long()\n",
    "\n",
    "        # Filter out invalid edge indices (indices out of bounds for available nodes)\n",
    "        valid_mask = (edge_index[0] < data[key[0]].x.shape[0]) & (edge_index[1] < data[key[2]].x.shape[0])\n",
    "        if not valid_mask.all():\n",
    "            print(f\"Warning: Edge index for {key} contains out of bounds indices, filtering them.\")\n",
    "        data.edge_index_dict[key] = edge_index[:, valid_mask]\n",
    "\n",
    "        # Check if any remaining edge index values are negative\n",
    "        if edge_index.min() < 0:\n",
    "            raise ValueError(f\"Edge index for {key} contains negative values, which are invalid.\")\n",
    "\n",
    "    # Move tensors to float32 if needed\n",
    "    data['domain_node'].x = data['domain_node'].x.float()\n",
    "    data['ip_node'].x = data['ip_node'].x.float()\n",
    "    data['host_node'].x = data['host_node'].x.float()\n",
    "\n",
    "    # Fix: Clamp negative values to zero to ensure all values are non-negative\n",
    "    data['domain_node'].x = torch.clamp(data['domain_node'].x, min=0)\n",
    "\n",
    "    # Debugging: Print tensor information before moving to device\n",
    "    print(f\"domain_node features before moving to device: shape={data['domain_node'].x.shape}, dtype={data['domain_node'].x.dtype}\")\n",
    "    print(f\"ip_node features before moving to device: shape={data['ip_node'].x.shape}, dtype={data['ip_node'].x.dtype}\")\n",
    "    print(f\"host_node features before moving to device: shape={data['host_node'].x.shape}, dtype={data['host_node'].x.dtype}\")\n",
    "\n",
    "    # Move the entire data object to device\n",
    "    try:\n",
    "        data = data.to(device)\n",
    "        print(f\"Moved data to {device} successfully.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error moving data to {device}: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Debugging: Print out device allocation\n",
    "    print(f\"Data device: {data['domain_node'].x.device}\")\n",
    "\n",
    "    x = data['domain_node'].x.cpu()\n",
    "    perf_arr = np.empty((6, 0))\n",
    "    val_nodes = np.array([1, 5, 20, 40, 60, 80, 100])\n",
    "    \n",
    "    # Initialize and train a new clean model\n",
    "    model0 = HeteroGNN(data.metadata(), hidden_channels=64, out_channels=2, num_layers=2)\n",
    "    model0 = model0.to(device)\n",
    "    data.x_dict2 = copy.deepcopy(data.x_dict)\n",
    "    data.edge_index_dict2 = copy.deepcopy(data.edge_index_dict)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(201):\n",
    "        loss = train(model0, data)\n",
    "\n",
    "    labels_sur = model_qurey(model0, data, idx_train)\n",
    "    labels_sur = np.array(labels_sur.cpu())\n",
    "\n",
    "    preds = preds_of_adv(model0, data, adv_nodes_test)\n",
    "\n",
    "    # Initialize and train a new surrogate\n",
    "    surrogate = GCN(nfeat=features_sur.shape[1], nclass=2, nhid=64, dropout=0, with_relu=False, with_bias=False, device='cpu')\n",
    "\n",
    "    # Move surrogate training data to CPU\n",
    "    features_sur_cpu = features_sur.to('cpu')\n",
    "    Adj_sur_cpu = Adj_sur.to('cpu')\n",
    "    labels_sur_cpu = labels_sur.to('cpu')\n",
    "    idx_train_cpu = idx_train.to('cpu')\n",
    "\n",
    "    # Train the surrogate model\n",
    "    surrogate.fit(features_sur_cpu, Adj_sur_cpu, labels_sur_cpu, idx_train_cpu)\n",
    "\n",
    "    # Loop over val_nodes and calculate performance metrics\n",
    "    for val in val_nodes: \n",
    "        temp0 = data.edge_index_dict2[('domain_node', 'apex', 'domain_node')]\n",
    "        temp0 = np.array(temp0.cpu())\n",
    "        node_list0 = temp0[0, :]\n",
    "\n",
    "        X = x[adv_nodes_test, :].cpu()\n",
    "        X = np.array(X)\n",
    "        A = A_adv\n",
    "        X2 = copy.deepcopy(X)\n",
    "        all_lox = np.arange(45)\n",
    "        w1 = surrogate.gc1\n",
    "        W = w1.weight.data\n",
    "        W1 = np.array(W.cpu())\n",
    "        F1 = find_my_soln(W1)\n",
    "\n",
    "        simi_arr = np.zeros([100, 100])\n",
    "        messages = np.dot(A, X2)\n",
    "\n",
    "        for i in range(100):\n",
    "            tempx = A[i, :]\n",
    "            js = np.flatnonzero(tempx)\n",
    "            for j in range(100):\n",
    "                W2 = copy.deepcopy(W1)\n",
    "                d_j = len(js)\n",
    "                F2 = 0 * F1\n",
    "                for kk in np.arange(len(js)):\n",
    "                    message_j = messages[js[kk], :]\n",
    "                W2 = copy.deepcopy(W1)\n",
    "                for kkk in np.arange(64):\n",
    "                    if d_j > 0:\n",
    "                        W2[:, kkk] = W1[:, kkk] - 1 / d_j * message_j\n",
    "\n",
    "                F2 = F2 + find_my_soln(W2)    \n",
    "                simi_arr[i, j] = np.linalg.norm(1 * F1 + 1 * F2)\n",
    "\n",
    "        largest_idx = largest_indices(simi_arr, val * val)\n",
    "        largest_idx = np.array(largest_idx)\n",
    "\n",
    "        m = np.zeros([100, 100])\n",
    "        for i in range(largest_idx.shape[1]):\n",
    "            m[largest_idx[0, i], largest_idx[1, i]] = 1\n",
    "\n",
    "        A2 = do_perturb_adj(A, m)\n",
    "        aa = A_to_edge_index(A2)\n",
    "        conv = np.zeros_like(aa)\n",
    "        for k in range(aa.shape[1]):\n",
    "            conv[0, k] = adv_nodes_test[aa[0, k]]\n",
    "            conv[1, k] = adv_nodes_test[aa[1, k]]\n",
    "\n",
    "        all_edges = temp0\n",
    "\n",
    "        adv_edge_lox = np.nonzero(np.in1d(all_edges[0, :], adv_nodes_test))[0]\n",
    "        non_adv_edges = np.delete(all_edges, adv_edge_lox, axis=1)\n",
    "        temp2 = np.hstack((non_adv_edges, conv))\n",
    "\n",
    "        temp2 = torch.tensor(temp2).to(device)\n",
    "        data.edge_index_dict2[('domain_node', 'apex', 'domain_node')] = temp2\n",
    "\n",
    "        # Update data and calculate ASR metrics\n",
    "        data = data.to(device)\n",
    "        ASRgood, num_of_1_forced_to_0, num_of_1, ASRbad, num_of_0_forced_to_1, num_of_0 = calc_ASR(data, adv_nodes_test, model0)\n",
    "\n",
    "        temp_res = np.array([ASRgood, num_of_1_forced_to_0, num_of_1, ASRbad, num_of_0_forced_to_1, num_of_0]).reshape(-1, 1)\n",
    "        perf_arr = np.hstack((perf_arr, temp_res))\n",
    "        \n",
    "    return perf_arr\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T02:28:14.157801Z",
     "start_time": "2024-11-11T02:28:10.360823Z"
    }
   },
   "source": [
    "Num=30\n",
    "\n",
    "adv_nodes=np.arange(100)+377654-100\n",
    "A_adv=np.eye(100)\n",
    "arr1=np.arange(1, 4+1)\n",
    "arr2=np.arange(10, 18+1)\n",
    "arr3=np.arange(20, 28+1)\n",
    "arr4=np.arange(29, 46+1)\n",
    "arr5=np.arange(47, 54+1)\n",
    "arr6=np.arange(62, 66+1)\n",
    "arr7=np.arange(67, 93+1)\n",
    "arr8=np.arange(94, 99+1)\n",
    "for i in range(len(arr1)):\n",
    "    for j in range(len(arr1)):\n",
    "        A_adv[arr1[i], arr1[j]]=1       \n",
    "for i in range(len(arr2)):\n",
    "    for j in range(len(arr2)):\n",
    "        A_adv[arr2[i], arr2[j]]=1        \n",
    "for i in range(len(arr3)):\n",
    "    for j in range(len(arr3)):\n",
    "        A_adv[arr3[i], arr3[j]]=1              \n",
    "for i in range(len(arr4)):\n",
    "    for j in range(len(arr4)):\n",
    "        A_adv[arr4[i], arr4[j]]=1\n",
    "\n",
    "for i in range(len(arr5)):\n",
    "    for j in range(len(arr5)):\n",
    "        A_adv[arr5[i], arr5[j]]=1       \n",
    "for i in range(len(arr6)):\n",
    "    for j in range(len(arr6)):\n",
    "        A_adv[arr6[i], arr6[j]]=1        \n",
    "for i in range(len(arr7)):\n",
    "    for j in range(len(arr7)):\n",
    "        A_adv[arr7[i], arr7[j]]=1              \n",
    "for i in range(len(arr8)):\n",
    "    for j in range(len(arr8)):\n",
    "        A_adv[arr8[i], arr8[j]]=1\n",
    "\n",
    "res_arr=np.zeros((Num, 6,7))\n",
    "for tri in range(Num):\n",
    "    print(tri)\n",
    "    g1=one_trial(adv_nodes, A_adv)\n",
    "    res_arr[tri,:,:]=g1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "domain_node features before moving to device: shape=torch.Size([377554, 45]), dtype=torch.float32\n",
      "ip_node features before moving to device: shape=torch.Size([76316, 1]), dtype=torch.float32\n",
      "host_node features before moving to device: shape=torch.Size([12035, 1]), dtype=torch.float32\n",
      "Error moving data to cuda: CUDA error: device-side assert triggered\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 42\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tri \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(Num):\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28mprint\u001B[39m(tri)\n\u001B[0;32m---> 42\u001B[0m     g1\u001B[38;5;241m=\u001B[39m\u001B[43mone_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43madv_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA_adv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m     res_arr[tri,:,:]\u001B[38;5;241m=\u001B[39mg1\n",
      "Cell \u001B[0;32mIn[25], line 56\u001B[0m, in \u001B[0;36mone_trial\u001B[0;34m(adv_nodes_test, A_adv)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# Move the entire data object to device\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 56\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMoved data to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m successfully.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch_geometric/data/data.py:360\u001B[0m, in \u001B[0;36mBaseData.to\u001B[0;34m(self, device, non_blocking, *args)\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto\u001B[39m(\u001B[38;5;28mself\u001B[39m, device: Union[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m], \u001B[38;5;241m*\u001B[39margs: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    356\u001B[0m        non_blocking: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    357\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;124;03m    only the ones given in :obj:`*args`.\u001B[39;00m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 360\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch_geometric/data/data.py:340\u001B[0m, in \u001B[0;36mBaseData.apply\u001B[0;34m(self, func, *args)\u001B[0m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001B[39;00m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;124;03mthe ones given in :obj:`*args`.\u001B[39;00m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m store \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstores:\n\u001B[0;32m--> 340\u001B[0m     \u001B[43mstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch_geometric/data/storage.py:201\u001B[0m, in \u001B[0;36mBaseStorage.apply\u001B[0;34m(self, func, *args)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;124;03mthe ones given in :obj:`*args`.\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems(\u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m--> 201\u001B[0m     \u001B[38;5;28mself\u001B[39m[key] \u001B[38;5;241m=\u001B[39m \u001B[43mrecursive_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch_geometric/data/storage.py:895\u001B[0m, in \u001B[0;36mrecursive_apply\u001B[0;34m(data, func)\u001B[0m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrecursive_apply\u001B[39m(data: Any, func: Callable) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    894\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, Tensor):\n\u001B[0;32m--> 895\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    896\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mrnn\u001B[38;5;241m.\u001B[39mPackedSequence):\n\u001B[1;32m    897\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(data)\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch_geometric/data/data.py:361\u001B[0m, in \u001B[0;36mBaseData.to.<locals>.<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto\u001B[39m(\u001B[38;5;28mself\u001B[39m, device: Union[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m], \u001B[38;5;241m*\u001B[39margs: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    356\u001B[0m        non_blocking: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    357\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;124;03m    only the ones given in :obj:`*args`.\u001B[39;00m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    360\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply(\n\u001B[0;32m--> 361\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;241m*\u001B[39margs)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.mean(res_arr, axis = 0)\n",
    "avg_mal_num=res_arr[:,2,:].mean()\n",
    "avg_ben_num=res_arr[:,5,:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_nodes=np.array([1,5,20,40,60,80,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 17\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_change_arr=val_nodes\n",
    "if not os.path.exists('RESULTS_adj_2_created_doms'):\n",
    "    os.makedirs('RESULTS_adj_2_created_doms')\n",
    "plt.figure(facecolor='white')\n",
    "plt.title(\"$\\it{apex}$ Edge Perturbation\")\n",
    "plt.xlabel(\"Domain nodes with perturbed edges\", weight='bold') \n",
    "plt.ylabel(\"ASR\", weight='bold') \n",
    "# plot the ASR:\n",
    "m0, l0, u0=confid_measures(arr1[:,0,:], 100)\n",
    "plt.plot(val_nodes, m0,'-og', label=(\"ASR\"))\n",
    "plt.fill_between(num_change_arr, l0, u0, color='green', alpha=0.2)\n",
    "plt.grid()\n",
    "plt.fill_between(num_change_arr, l0, u0, color='green', alpha=0.2)\n",
    "legend_text = 'Mal. doms: %.1f' % (29.57)\n",
    "plt.legend(loc='lower right', fontsize=\"11\",prop=dict(weight='bold'),title=legend_text)\n",
    "name='RESULTS_adj_2_created_doms/asr_plot1_'+ str(Num)+'_trials_ras.png'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "name='RESULTS_adj_2_created_doms/asr_plot1_'+ str(Num)+'_trials_ras.pdf'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot NFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='white')\n",
    "plt.title(\"$\\it{apex}$ Edge Perturbation\")\n",
    "plt.xlabel(\"Domain nodes with perturbed edges\", weight='bold') \n",
    "plt.ylabel(\"NFR\", weight='bold') \n",
    "m3, l3, u3=confid_measures(arr1[:,3,:], 100)\n",
    "plt.plot(val_nodes, m3,'-xr', label=(\"NFR\"))\n",
    "plt.fill_between(num_change_arr, l3, u3, color='red', alpha=0.2)\n",
    "legend_text = 'Undetected doms: %.1f' % (70.43)\n",
    "plt.legend(loc='upper left', fontsize=\"11\",prop=dict(weight='bold'),title=legend_text)\n",
    "plt.grid()\n",
    "name='RESULTS_adj_2_created_doms/asr_plot3_'+ str(Num)+'_trials_ras.png'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "name='RESULTS_adj_2_created_doms/asr_plot3_'+ str(Num)+'_trials_ras.pdf'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr=m0\n",
    "fpr=m3\n",
    "plt.figure(facecolor='white')\n",
    "plt.title(\"NFR-ASR ROC\")\n",
    "plt.xlabel(\"NFR\", weight='bold') \n",
    "plt.ylabel(\"ASR\", weight='bold') \n",
    "m3, l3, u3=confid_measures(arr1[:,3,:], 100)\n",
    "plt.plot(fpr, tpr) \n",
    "plt.grid()\n",
    "name='RESULTS_adj_2_created_doms/ROC_rel_4'+ str(Num)+'.png'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "name='RESULTS_adj_2_created_doms/ROC_rel_4'+ str(Num)+'.pdf'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

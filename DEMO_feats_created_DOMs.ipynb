{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pertubation of features-created domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T04:52:03.596958Z",
     "start_time": "2024-11-07T04:52:01.432266Z"
    }
   },
   "source": [
    "from src.loader import load_graph\n",
    "from classes import extract_all_features_single \n",
    "import sys\n",
    "import os\n",
    "from src import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from src.utils import largest_indices\n",
    "from src.utils import cal_n_add_facni \n",
    "from src.utils import extract_feat_adj2\n",
    "from src.utils import calc_cad \n",
    "import networkx as nx\n",
    "from scipy import spatial\n",
    "import copy  \n",
    "from matplotlib import pyplot as plt \n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routines"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T04:52:16.155869Z",
     "start_time": "2024-11-07T04:52:16.141517Z"
    }
   },
   "source": [
    "def confid_measures(arr_tri, Num):\n",
    "    arr_tri_mean=np.mean(arr_tri,axis=0)\n",
    "    std=np.std(arr_tri,axis=0)\n",
    "    Z=1.960 # for 95 conf.\n",
    "    upper=arr_tri_mean+Z*std/np.sqrt(Num)\n",
    "    lower=arr_tri_mean-Z*std/np.sqrt(Num)\n",
    "    return arr_tri_mean, lower, upper\n",
    "\n",
    "def my_score(pred, labels):\n",
    "    accuracy = (pred == labels).sum() / len(pred)\n",
    "    return accuracy\n",
    "def my_own_acc(a, b):\n",
    "    acc = np.sum(np.equal(a, b)) / len(a)\n",
    "    return acc\n",
    "\n",
    "def do_perturb_feat(x,m):\n",
    "    x_bol=np.array(x, dtype=bool);\n",
    "    m_bol=np.array(m, dtype=bool);\n",
    "#     x2=np.logical_or(x_bol,m_bol)\n",
    "    x2=np.logical_xor(x_bol,m_bol)\n",
    "    x2=x2.astype(float)\n",
    "    x2=torch.from_numpy(x2)\n",
    "    return x2\n",
    "\n",
    "def do_perturb_adj(a,m):\n",
    "    a_bol=np.array(a, dtype=bool);\n",
    "    m_bol=np.array(m, dtype=bool);\n",
    "    a2=np.logical_xor(a_bol,m_bol)\n",
    "    a2=a2.astype(float)\n",
    "    a2=torch.from_numpy(a2)\n",
    "    return a2\n",
    "\n",
    "def A_to_edge_index(A):\n",
    "    G=nx.from_numpy_matrix(A)\n",
    "    edge_index=list(G.edges)\n",
    "    z=torch.tensor(np.transpose(edge_index))\n",
    "    return z\n",
    "\n",
    "def assign_Adversary_nas_mal(data, norm_zero_int):\n",
    "\n",
    "    test_mask = data['domain_node']['test_mask']\n",
    "    labels_test=data['domain_node'].y[test_mask].cpu()\n",
    "    lox_test=np.where(test_mask.cpu()>0)\n",
    "    lox_test=lox_test[0]\n",
    "    labels=data['domain_node'].y.cpu()\n",
    "\n",
    "    lox_test_space=lox_test[np.where(labels_test.cpu()==1) ] #mal\n",
    "\n",
    "    adv_nodes_test=random.sample(set(lox_test_space), norm_zero_int)\n",
    "    \n",
    "    return adv_nodes_test\n",
    "\n",
    "def get_As_new(adj_1, adj_2, adj_3, adj_4, adv_nodes):\n",
    "    \n",
    "    edge_list= np.concatenate(( adj_2.cpu(), adj_4.cpu()), axis=1)\n",
    "   \n",
    "    all_edges1=edge_list[0,:]\n",
    "    all_edges2=edge_list[1,:]\n",
    "\n",
    "    adv_edge_lox1= np.nonzero(np.in1d(all_edges1, adv_nodes))[0]\n",
    "    adv_edge_lox2= np.nonzero(np.in1d(all_edges2, adv_nodes))[0]\n",
    "    A_adv=np.zeros( (len(adv_nodes),len(adv_nodes)), dtype=int)\n",
    "    adv_nodes=np.array(adv_nodes)\n",
    "    adv_edge_lox1=np.array(adv_edge_lox1)\n",
    "    adv_edge_lox2=np.array(adv_edge_lox2)\n",
    "\n",
    "    for k in range(adv_edge_lox1.shape[0]):\n",
    "        a=all_edges1[adv_edge_lox1[k]]\n",
    "        b=all_edges2[adv_edge_lox2[k]]\n",
    "        lox_a=np.where(adv_nodes == np.array(a))\n",
    "        lox_b=np.where(adv_nodes == np.array(b))\n",
    "        A_adv[lox_a,lox_b]=1 \n",
    "    print(\"resssss\", np.count_nonzero(A_adv))\n",
    "   \n",
    "    return A_adv\n",
    "\n",
    "def extract_A(data, adv_nodes):\n",
    "    edge_list_1=data.edge_index_dict['domain_node', 'apex', 'domain_node'][0,:]\n",
    "    edge_list=data.edge_index_dict['domain_node', 'apex', 'domain_node']\n",
    "    common_node_lox=np.nonzero(np.in1d(edge_list_1.cpu(), adv_nodes))[0]\n",
    "    adv_edge_list=edge_list[:,common_node_lox]\n",
    "    A_adv=edge_list_to_adj(adv_edge_list.cpu())\n",
    "    return A_adv\n",
    "\n",
    "def edge_list_to_adj(adv_edge_lox1, adv_edge_lox2):\n",
    "    elist=adv_edge_lox2\n",
    "    print(elist)\n",
    "    domain_node_list=np.unique(elist)\n",
    "    domain_node_list=domain_node_list[0:4000]\n",
    "    A=np.zeros( (len(domain_node_list),len(domain_node_list)), dtype=int)\n",
    "    for k in range(len(elist)):\n",
    "        a=adv_edge_lox1[k]\n",
    "        b=adv_edge_lox2[k]\n",
    "        lox_a=np.where(domain_node_list == a)\n",
    "        lox_b=np.where(domain_node_list == b)\n",
    "        A[lox_a,lox_b]=1\n",
    "    return A\n",
    "\n",
    "def extract_As_jan(data, adv_nodes):\n",
    "    edge_list=data.edge_index_dict['domain_node', 'apex', 'domain_node']\n",
    "    all_edges1=edge_list[0,:]\n",
    "    all_edges2=edge_list[1,:] \n",
    "    all_edges1=all_edges1.cpu()\n",
    "    all_edges2=all_edges2.cpu()\n",
    "    adv_edge_lox1= np.nonzero(np.in1d(all_edges1, adv_nodes))[0]\n",
    "    adv_edge_lox2= np.nonzero(np.in1d(all_edges2, adv_nodes))[0]\n",
    "    L=len(adv_nodes)\n",
    "    A_adv1=np.zeros( (L,L), dtype=int)\n",
    "    adv_nodes=np.array(adv_nodes)\n",
    "    adv_edge_lox1=np.array(adv_edge_lox1)\n",
    "    adv_edge_lox2=np.array(adv_edge_lox2)\n",
    "\n",
    "    for k in range(adv_edge_lox1.shape[0]):\n",
    "        a=all_edges1[adv_edge_lox1[k]]\n",
    "        b=all_edges2[adv_edge_lox2[k]]\n",
    "        lox_a=np.where(adv_nodes == np.array(a))\n",
    "        lox_b=np.where(adv_nodes == np.array(b))\n",
    "        A_adv1[lox_a,lox_b]=1     \n",
    "    print(\"sparsity\", np.count_nonzero(A_adv1))    \n",
    "    \n",
    "    \n",
    "    edge_list=data.edge_index_dict['domain_node', 'similar', 'domain_node']\n",
    "    all_edges1=edge_list[0,:]\n",
    "    all_edges2=edge_list[1,:]\n",
    "    \n",
    "    all_edges1=all_edges1.cpu()\n",
    "    all_edges2=all_edges2.cpu()\n",
    "\n",
    "    adv_edge_lox1= np.nonzero(np.in1d(all_edges1, adv_nodes))[0]\n",
    "    adv_edge_lox2= np.nonzero(np.in1d(all_edges2, adv_nodes))[0]\n",
    "\n",
    "    L=len(adv_nodes)\n",
    "    A_adv2=np.zeros( (L,L), dtype=int)\n",
    "    adv_nodes=np.array(adv_nodes)\n",
    "    adv_edge_lox1=np.array(adv_edge_lox1)\n",
    "    adv_edge_lox2=np.array(adv_edge_lox2)\n",
    "\n",
    "    for k in range(adv_edge_lox1.shape[0]):\n",
    "        a=all_edges1[adv_edge_lox1[k]]\n",
    "        b=all_edges2[adv_edge_lox2[k]]\n",
    "        lox_a=np.where(adv_nodes == np.array(a))\n",
    "        lox_b=np.where(adv_nodes == np.array(b))\n",
    "        A_adv2[lox_a,lox_b]=1\n",
    "        \n",
    "    print(\"sparsity\", np.count_nonzero(A_adv2)) \n",
    "    \n",
    "    \n",
    "    A_adv=A_adv1+A_adv2\n",
    "    \n",
    "    return A_adv\n",
    "\n",
    "\n",
    "def find_my_soln(WW):\n",
    "    ATA=np.dot(WW,WW.T)\n",
    "    w, v=np.linalg.eig(ATA)\n",
    "    return v[:,0]\n",
    "\n",
    "def calc_ASR(data, adv_nodes_test, model0):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model0.eval()\n",
    "        pred_raw0 = model0(data.x_dict, data.edge_index_dict)\n",
    "        pred_raw0 = F.softmax(pred_raw0, dim=1)\n",
    "        y0_hat= pred_raw0.argmax(dim=-1)\n",
    "        \n",
    "    y0_hat=y0_hat[adv_nodes_test]    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        model0.eval()\n",
    "        pred_raw2 = model0(data.x_dict2, data.edge_index_dict)\n",
    "        pred_raw2 = F.softmax(pred_raw2, dim=1)\n",
    "        y2_hat= pred_raw2.argmax(dim=-1)\n",
    "    y2_hat=y2_hat[adv_nodes_test]        \n",
    "\n",
    "    num_of_1=0;\n",
    "    num_of_1_forced_to_0=0;\n",
    "    num_of_0=0;\n",
    "    num_of_0_forced_to_1=0;\n",
    "    \n",
    "    for jj in range(len(y0_hat)):\n",
    "        if y0_hat[jj]==1:\n",
    "            num_of_1=num_of_1+1\n",
    "        if y0_hat[jj]==1 and y2_hat[jj]==0:\n",
    "            num_of_1_forced_to_0=num_of_1_forced_to_0+1;\n",
    "            \n",
    "        if y0_hat[jj]==0:\n",
    "            num_of_0=num_of_0+1\n",
    "        if y0_hat[jj]==0 and y2_hat[jj]==1:\n",
    "            num_of_0_forced_to_1=num_of_0_forced_to_1+1;\n",
    "            \n",
    "    if num_of_1>0:\n",
    "        ASRgood=num_of_1_forced_to_0/num_of_1\n",
    "    else:\n",
    "        ASRgood=num_of_1_forced_to_0\n",
    "\n",
    "        \n",
    "    if num_of_0>0:\n",
    "        ASRbad=num_of_0_forced_to_1/num_of_0\n",
    "    else:\n",
    "        ASRbad=num_of_0_forced_to_1\n",
    "        \n",
    "    print(\"ASRgood\", ASRgood, num_of_1_forced_to_0, num_of_1, \"ASRbad\", ASRbad, num_of_0_forced_to_1, num_of_0)\n",
    "    return ASRgood, num_of_1_forced_to_0, num_of_1, ASRbad, num_of_0_forced_to_1, num_of_0\n",
    "def flip_the_bins(x,lox):\n",
    "    m=np.zeros_like(x)\n",
    "    m[:,lox]=1\n",
    "    x_bol=np.array(x, dtype=bool);\n",
    "    m_bol=np.array(m, dtype=bool);\n",
    "    x2=np.logical_xor(x_bol,m_bol)\n",
    "    x2=x2.astype(float)\n",
    "    x2=torch.from_numpy(x2)\n",
    "    return x2\n",
    "\n",
    "def preds_of_adv(model0, data, adv_nodes_test):\n",
    "    with torch.no_grad():\n",
    "        model0.eval()\n",
    "    pred_raw0 = model0(data.x_dict, data.edge_index_dict)\n",
    "    y0_hat= pred_raw0.argmax(dim=-1)\n",
    "    preds=y0_hat[adv_nodes_test]\n",
    "    return preds\n",
    "def model_qurey(model, data, idx_train):\n",
    "    model.eval()\n",
    "    pred_raw2 = model(data.x_dict2, data.edge_index_dict)\n",
    "    pred_raw2 = F.softmax(pred_raw2, dim=1)\n",
    "    y2_hat= pred_raw2.argmax(dim=-1)\n",
    "    labels_sur=y2_hat[idx_train]\n",
    "    \n",
    "    return labels_sur"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T05:00:27.253662Z",
     "start_time": "2024-11-07T05:00:23.546585Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.loader2 import DNS2\n",
    "kg_path = lambda graph_name: f'/home/sucharitha/MintA/myGraph_datasets/{graph_name}'\n",
    "dataset = DNS2('myGraph_datasets/DNS', transform=T.Compose([T.NormalizeFeatures(), T.ToUndirected()]), balance_gt=True)\n",
    "data = dataset[0]\n",
    "# dir(data)\n",
    "# feats_2=cal_n_add_facni(kg_path('DNS_eid_adv'), data);\n",
    "# torch.save(feats_2, 'feats_2.pt')\n",
    "# This script is for eature extraction\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# dir(data)\n",
    "# feats_new2=cal_n_add_facni(kg_path('DNS_eid_adv'), data);\n",
    "# torch.save(feats_new2, 'feats_new2.pt')\n",
    "\n",
    "# Feature assignment \n",
    "feats_new2=torch.load('feats_new2.pt')\n",
    "data['domain_node'].x= feats_new2[0:data.x_dict['domain_node'].shape[0],:]\n",
    "data['ip_node'].x=torch.zeros(data['ip_node'].x.shape[0],1)\n",
    "data['host_node'].x=torch.zeros(data['host_node'].x.shape[0],1)\n",
    "del feats_new2\n",
    "# print(data.metadata)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MDD model "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T05:02:23.981382Z",
     "start_time": "2024-11-07T05:02:23.933695Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv, HeteroConv, Linear\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels, num_layers, add_self_loops=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: GATConv((-1,-1), hidden_channels, add_self_loops=add_self_loops)\n",
    "                for edge_type in metadata[1]\n",
    "            })\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['domain_node'])\n",
    "    \n",
    "model = HeteroGNN(data.metadata(), hidden_channels=64, out_channels=2,\n",
    "                  num_layers=2)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T05:02:31.966873Z",
     "start_time": "2024-11-07T05:02:31.429362Z"
    }
   },
   "source": [
    "torch.cuda.set_device(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data=data.to(device)\n",
    "model=model.to(device)\n",
    "\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "           \n",
    "def train(model,data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['domain_node'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['domain_node'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask', 'test_mask']:\n",
    "        mask = data[split]\n",
    "        acc = (pred[mask] == data['domain_node'].y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T05:02:36.465666Z",
     "start_time": "2024-11-07T05:02:36.157781Z"
    }
   },
   "source": [
    "from deeprobust.graph.defense import GCN\n",
    "# datya to train the surrog\n",
    "train_mask = data['domain_node'].train_mask\n",
    "labels_train=data['domain_node'].y.cpu()\n",
    "labelled_labels_train_lox=np.where(labels_train<2)\n",
    "lox_train=np.where(train_mask.cpu()>0)\n",
    "lox_train=lox_train[0]\n",
    "labels=data['domain_node'].y.cpu()\n",
    "lox_train_space=labelled_labels_train_lox\n",
    "adv_nodes_train=lox_train_space[0][0:4000]\n",
    "Adj_sur=extract_As_jan(data, adv_nodes_train)\n",
    "features_sur=data['domain_node'].x[adv_nodes_train]\n",
    "features_sur=np.array(features_sur.cpu())\n",
    "data.x_sur=features_sur\n",
    "idx_train=np.arange(4000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity 3802\n",
      "sparsity 2322\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The proposed MinstA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T05:02:45.423237Z",
     "start_time": "2024-11-07T05:02:45.414897Z"
    }
   },
   "source": [
    "def one_trial(adv_nodes_test):\n",
    "    \n",
    "    # init and a train a new model instance\n",
    "    dataset = DNS2('myGraph_datasets/DNS', transform=T.Compose([T.NormalizeFeatures(), T.ToUndirected()]), balance_gt=True)\n",
    "    data = dataset[0]\n",
    "    feats_new=torch.load('feats_new2.pt')\n",
    "    data['domain_node'].x= feats_new[0:data.x_dict['domain_node'].shape[0],:]\n",
    "    data['ip_node'].x=torch.zeros(data['ip_node'].x.shape[0],1)\n",
    "    data['host_node'].x=torch.zeros(data['host_node'].x.shape[0],1)\n",
    "    del feats_new\n",
    "        \n",
    "    perf_arr=np.empty((6,0))\n",
    "    val_nodes=np.array([1,5,20,40,60,80,100])\n",
    "    \n",
    "        # init and train a new clean model:\n",
    "    model0= HeteroGNN(data.metadata(), hidden_channels=64, out_channels=2, num_layers=2)\n",
    "    data, model0 = data.to(device), model0.to(device)\n",
    "    data.x_dict2=copy.deepcopy(data.x_dict)\n",
    "    \n",
    "    for epoch in range(201):\n",
    "        loss=train(model0,data)\n",
    "        \n",
    "    labels_sur=model_qurey(model0, data, idx_train)\n",
    "    labels_sur=np.array(labels_sur.cpu())\n",
    "    \n",
    "    preds=preds_of_adv(model0, data, adv_nodes_test)\n",
    "\n",
    "    # init and train a new surrogate\n",
    "    surrogate = GCN(nfeat=features_sur.shape[1], nclass=2,\n",
    "                nhid=64, dropout=0, with_relu=False, with_bias=False, device='cpu')\n",
    "    surrogate.fit(features_sur, Adj_sur, labels_sur, idx_train)\n",
    "\n",
    "    \n",
    "\n",
    "    A_adv=np.eye(100)\n",
    "    arr1=np.arange(1, 4+1)\n",
    "    arr2=np.arange(10, 18+1)\n",
    "    arr3=np.arange(20, 28+1)\n",
    "    arr4=np.arange(29, 46+1)\n",
    "    arr5=np.arange(47, 54+1)\n",
    "    arr6=np.arange(62, 66+1)\n",
    "    arr7=np.arange(67, 93+1)\n",
    "    arr8=np.arange(94, 99+1)\n",
    "\n",
    "    for i in range(len(arr1)):\n",
    "        for j in range(len(arr1)):\n",
    "            A_adv[arr1[i], arr1[j]]=1       \n",
    "    for i in range(len(arr2)):\n",
    "        for j in range(len(arr2)):\n",
    "            A_adv[arr2[i], arr2[j]]=1        \n",
    "    for i in range(len(arr3)):\n",
    "        for j in range(len(arr3)):\n",
    "            A_adv[arr3[i], arr3[j]]=1              \n",
    "    for i in range(len(arr4)):\n",
    "        for j in range(len(arr4)):\n",
    "            A_adv[arr4[i], arr4[j]]=1\n",
    "\n",
    "    for i in range(len(arr5)):\n",
    "        for j in range(len(arr5)):\n",
    "            A_adv[arr5[i], arr5[j]]=1       \n",
    "    for i in range(len(arr6)):\n",
    "        for j in range(len(arr6)):\n",
    "            A_adv[arr6[i], arr6[j]]=1        \n",
    "    for i in range(len(arr7)):\n",
    "        for j in range(len(arr7)):\n",
    "            A_adv[arr7[i], arr7[j]]=1              \n",
    "    for i in range(len(arr8)):\n",
    "        for j in range(len(arr8)):\n",
    "            A_adv[arr8[i], arr8[j]]=1\n",
    "   \n",
    "    for val in val_nodes: \n",
    "        print(val)\n",
    "        x=data['domain_node'].x.cpu()\n",
    "        x2=copy.deepcopy(x)\n",
    "        X=x[adv_nodes_test,:].cpu()\n",
    "        X=np.array(X)\n",
    "        A=A_adv\n",
    "        X2=copy.deepcopy(X)\n",
    "        all_lox=np.arange(45)\n",
    "        w1=surrogate.gc1\n",
    "        W=w1.weight.data\n",
    "        W1=np.array(W.cpu())\n",
    "        F1=find_my_soln(W1)\n",
    "\n",
    "        for zzz in range(1):\n",
    "            for i in np.arange(val):\n",
    "                if preds[i]>0:\n",
    "                    temp=A[i,:];\n",
    "                    js=np.flatnonzero(temp) \n",
    "                #     print(\"js\", js)\n",
    "                    messages=np.dot(A, X2)\n",
    "                    F2=0*F1\n",
    "                    for kk in np.arange(len(js)):\n",
    "                        message_j=messages[js[kk],:]\n",
    "\n",
    "                        W2=copy.deepcopy(W1)\n",
    "                        d_j=len(js)\n",
    "                #         F2=copy.deepcopy(F1)\n",
    "                        for kkk in np.arange(64):\n",
    "                            if d_j>0:\n",
    "                                W2[:,kkk]=W1[:,kkk]-1/d_j*message_j\n",
    "                            F2=F2+find_my_soln(W2)    \n",
    "                    feat_up=(1*F1+1*F2)/2\n",
    "                    X2[i,:]=X2[i,:]+feat_up[:]   \n",
    "\n",
    "        x2[adv_nodes_test,:]=torch.from_numpy(X2)  \n",
    "        x2=x2.to(device)\n",
    "        data.x_dict2['domain_node']=x2\n",
    "        ASRgood, num_of_1_forced_to_0, num_of_1, ASRbad, num_of_0_forced_to_1, num_of_0=calc_ASR(data, adv_nodes_test, model0) \n",
    "\n",
    "        temp=np.array([ASRgood, num_of_1_forced_to_0, num_of_1, ASRbad, num_of_0_forced_to_1, num_of_0]).reshape(-1,1)\n",
    "        perf_arr = np.hstack((perf_arr, temp))\n",
    "        \n",
    "    return perf_arr    "
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T05:03:12.474340Z",
     "start_time": "2024-11-07T05:02:57.645496Z"
    }
   },
   "source": [
    "Num=30\n",
    "res_arr=np.zeros((Num, 6,7))\n",
    "for tri in range(Num):    \n",
    "    adv_nodes=np.arange(100)+377654-100\n",
    "    g1=one_trial(adv_nodes)\n",
    "    res_arr[tri,:,:]=g1"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [96,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [97,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [98,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [99,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [32,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [33,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [34,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [35,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [36,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [37,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [38,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [39,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [40,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [41,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [42,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [43,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [44,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [45,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [46,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [47,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [48,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [49,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [50,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [51,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [52,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [53,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [54,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [55,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [56,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [57,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [58,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [59,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [60,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [61,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [62,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [63,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [0,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [1,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [2,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [3,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [4,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [5,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [6,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [7,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [8,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [9,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [10,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [11,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [12,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [13,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [14,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [15,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [16,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [17,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [18,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [19,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [20,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [21,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [22,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [23,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [24,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [25,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [26,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [27,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [28,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [29,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [30,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [31,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [64,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [65,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [66,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [67,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [68,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [69,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [70,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [71,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [72,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [73,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [74,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [75,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [76,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [77,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [78,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [79,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [80,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [81,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [82,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [83,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [84,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [85,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [86,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [87,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [88,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [89,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [90,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [91,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [92,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [93,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [94,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [95,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tri \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(Num):    \n\u001B[1;32m      4\u001B[0m     adv_nodes\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m100\u001B[39m)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m377654\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m\n\u001B[0;32m----> 5\u001B[0m     g1\u001B[38;5;241m=\u001B[39m\u001B[43mone_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43madv_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     res_arr[tri,:,:]\u001B[38;5;241m=\u001B[39mg1\n",
      "Cell \u001B[0;32mIn[7], line 31\u001B[0m, in \u001B[0;36mone_trial\u001B[0;34m(adv_nodes_test)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# init and train a new surrogate\u001B[39;00m\n\u001B[1;32m     29\u001B[0m surrogate \u001B[38;5;241m=\u001B[39m GCN(nfeat\u001B[38;5;241m=\u001B[39mfeatures_sur\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], nclass\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     30\u001B[0m             nhid\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, with_relu\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, with_bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 31\u001B[0m \u001B[43msurrogate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures_sur\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mAdj_sur\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_sur\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m A_adv\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39meye(\u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m     36\u001B[0m arr1\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/deeprobust/graph/defense/gcn.py:189\u001B[0m, in \u001B[0;36mGCN.fit\u001B[0;34m(self, features, adj, labels, idx_train, idx_val, train_iters, initialize, verbose, normalize, patience, **kwargs)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels \u001B[38;5;241m=\u001B[39m labels\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m idx_val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 189\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_without_val\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_iters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    191\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m patience \u001B[38;5;241m<\u001B[39m train_iters:\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/deeprobust/graph/defense/gcn.py:204\u001B[0m, in \u001B[0;36mGCN._train_without_val\u001B[0;34m(self, labels, idx_train, train_iters, verbose)\u001B[0m\n\u001B[1;32m    202\u001B[0m loss_train \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mnll_loss(output[idx_train], labels[idx_train])\n\u001B[1;32m    203\u001B[0m loss_train\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m--> 204\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;129;01mand\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, training loss: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i, loss_train\u001B[38;5;241m.\u001B[39mitem()))\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    387\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    388\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    389\u001B[0m             )\n\u001B[0;32m--> 391\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    394\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch/optim/adam.py:143\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;129m@_use_grad_for_differentiable\u001B[39m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, closure\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    137\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Perform a single optimization step.\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \n\u001B[1;32m    139\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;124;03m            and returns the loss.\u001B[39;00m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 143\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_graph_capture_health_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch/optim/optimizer.py:339\u001B[0m, in \u001B[0;36mOptimizer._cuda_graph_capture_health_check\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_graph_capture_health_check\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;66;03m# Note [torch.compile x capturable]\u001B[39;00m\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    336\u001B[0m     \u001B[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001B[39;00m\n\u001B[1;32m    337\u001B[0m     \u001B[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001B[39;00m\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling() \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_built() \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m--> 339\u001B[0m         capturing \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_current_stream_capturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    341\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m capturing \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups):\n\u001B[1;32m    342\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[1;32m    343\u001B[0m                                \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[1;32m    344\u001B[0m                                \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but param_groups\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m capturable is False.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/MintA/venv_minta/lib/python3.10/site-packages/torch/cuda/graphs.py:28\u001B[0m, in \u001B[0;36mis_current_stream_capturing\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_current_stream_capturing\u001B[39m():\n\u001B[1;32m     24\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_cuda_isCurrentStreamCapturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.mean(res_arr, axis = 0)\n",
    "avg_mal_num=res_arr[:,2,:].mean()\n",
    "avg_ben_num=res_arr[:,5,:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_nodes=np.array([1,5,20,40,60,80,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 17\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_change_arr=val_nodes\n",
    "\n",
    "if not os.path.exists('RESULTS_feat_creatd_doms'):\n",
    "    os.makedirs('RESULTS_feat_creatd_doms')\n",
    "plt.figure(facecolor='white')\n",
    "plt.title(\"Feature Perturbation\")\n",
    "plt.xlabel(\"Domain nodes with perturbed edges\", weight='bold') \n",
    "plt.ylabel(\"ASR\", weight='bold') \n",
    "# plot the ASR:\n",
    "m0, l0, u0=confid_measures(res_arr[:,0,:], Num)\n",
    "plt.plot(val_nodes, m0,'-og', label=('ASR'))\n",
    "plt.fill_between(num_change_arr, l0, u0, color='green', alpha=0.2)\n",
    "plt.grid()\n",
    "legend_text = 'Mal. doms: %.1f' % (arr1[2,0])\n",
    "plt.legend(loc='lower right',prop=dict(weight='bold'),title=legend_text,  fontsize=\"20\")\n",
    "name='RESULTS_feat_creatd_doms/asr_plot1_'+ str(Num)+'_trials.png'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "name='RESULTS_feat_creatd_doms/asr_plot1_'+ str(Num)+'_trials.pdf'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot NFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_change_arr=val_nodes\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "ax.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "plt.title(\"Feature Perturbation\")\n",
    "plt.xlabel(\"Domain nodes with perturbed edges\", weight='bold') \n",
    "plt.ylabel(\"NFR\", weight='bold') \n",
    "m3, l3, u3=confid_measures(res_arr[:,3,:], Num)\n",
    "ax.plot(val_nodes, m3,'-xr', label=(\"NFR\"))\n",
    "ax.fill_between(num_change_arr, l3, u3, color='red', alpha=0.2)\n",
    "ax.grid()\n",
    "legend_text = 'Undetected doms: %.1f' % (arr1[5,0])\n",
    "plt.legend(loc='upper left', fontsize=\"11\",prop=dict(weight='bold'),title=legend_text)\n",
    "name='RESULTS_feat_creatd_doms/asr_plot3_'+ str(Num)+'_trials_.png'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "name='RESULTS_feat_creatd_doms/asr_plot3_'+ str(Num)+'_trials_.pdf'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr=m0\n",
    "fpr=m3\n",
    "plt.figure(facecolor='white')\n",
    "plt.title(\"NFR-ASR ROC\")\n",
    "plt.xlabel(\"NFR\", weight='bold') \n",
    "plt.ylabel(\"ASR\", weight='bold') \n",
    "m3, l3, u3=confid_measures(res_arr[:,3,:], 100)\n",
    "plt.plot(fpr, tpr) \n",
    "plt.grid()\n",
    "name='RESULTS_feat_creatd_doms/feat_ROC_mydoms'+ str(Num)+'.png'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "name='RESULTS_feat_creatd_doms/feat_ROC_mydoms'+ str(Num)+'.pdf'\n",
    "plt.savefig(name, dpi=150, bbox_inches = 'tight') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
